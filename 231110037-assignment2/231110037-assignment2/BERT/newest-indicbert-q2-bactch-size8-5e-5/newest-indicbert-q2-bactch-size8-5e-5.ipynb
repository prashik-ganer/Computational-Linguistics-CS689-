{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6a3933734e754f35aeb5db5bc75b1ce5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eca0979ed2c340d4a0d10a43fe70e480","IPY_MODEL_867dd089e3834269a9b7ff07d9a4efdd","IPY_MODEL_b7b9d20653494bf0812675c515a59f10"],"layout":"IPY_MODEL_6e69da8e972b4e04a3245924c6c2c8b6"}},"eca0979ed2c340d4a0d10a43fe70e480":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ff49fcc3d9244a9b2f63df58fcb7a33","placeholder":"​","style":"IPY_MODEL_1478116babd446adb4cbdd8a39c45b75","value":"Running tokenizer on test dataset of language hi (num_proc=25): 100%"}},"867dd089e3834269a9b7ff07d9a4efdd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed205612faad4284ae9588ae0325f81e","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7dbb4fd5d4f44870ac4a80304e5ef5aa","value":25}},"b7b9d20653494bf0812675c515a59f10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a2f1a4d6b1f400b899392d1c3f638d1","placeholder":"​","style":"IPY_MODEL_9349bf22e8a34e88b33328b72134edd8","value":" 25/25 [00:01&lt;00:00, 24.72 examples/s]"}},"6e69da8e972b4e04a3245924c6c2c8b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ff49fcc3d9244a9b2f63df58fcb7a33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1478116babd446adb4cbdd8a39c45b75":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed205612faad4284ae9588ae0325f81e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dbb4fd5d4f44870ac4a80304e5ef5aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a2f1a4d6b1f400b899392d1c3f638d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9349bf22e8a34e88b33328b72134edd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install transformers\n!pip3 install datasets\n!pip3 install sentencepiece\n!pip3 install seqeval\n!pip install transformers[torch]\n!pip install accelerate -U","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xgt-Jar0rfy6","outputId":"a0480fd8-317b-406d-90e7-8e39e0bb8599","execution":{"iopub.status.busy":"2024-03-13T08:23:18.178821Z","iopub.execute_input":"2024-03-13T08:23:18.179175Z","iopub.status.idle":"2024-03-13T08:24:37.266187Z","shell.execute_reply.started":"2024-03-13T08:23:18.179145Z","shell.execute_reply":"2024-03-13T08:24:37.264995Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m661.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=0955a00a84398c5036878b9e6d63580aa3494a377bc38dcc6baed849a44ee2d2\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.27.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.27.2)\nCollecting accelerate\n  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.20.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.27.2\n    Uninstalling accelerate-0.27.2:\n      Successfully uninstalled accelerate-0.27.2\nSuccessfully installed accelerate-0.28.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#Naampadam Dataset\n","metadata":{"id":"WVKWwiOWr8gu"}},{"cell_type":"code","source":"# Let's download the Naampadam (Indic NER) dataset\nfrom datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n\nlang='hi'\n\nraw_datasets = load_dataset('ai4bharat/naamapadam', lang)","metadata":{"id":"Qz42pJAVr9Mx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea9ee87e-93ad-474c-a274-e8c58ea1c722","execution":{"iopub.status.busy":"2024-03-13T08:24:46.595698Z","iopub.execute_input":"2024-03-13T08:24:46.596081Z","iopub.status.idle":"2024-03-13T08:28:11.545899Z","shell.execute_reply.started":"2024-03-13T08:24:46.596049Z","shell.execute_reply":"2024-03-13T08:28:11.545005Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f635019556b040eeacd1784946417bf5"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset naamapadam_pr/hi to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/hi/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/82.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55215c09cba54ec1be404901e78447a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset naamapadam_pr downloaded and prepared to /root/.cache/huggingface/datasets/ai4bharat___naamapadam_pr/hi/1.0.0/99b5ec77eabfaa3fbff510d8cf70d7c34519486cb7dbee99ede19474ddff9b20. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a4183cb6a7745aa84a2570504ef4075"}},"metadata":{}}]},{"cell_type":"code","source":"# let's now print how the Dataset looks like\nraw_datasets","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBHgLiQGsBDU","outputId":"dba161da-2355-4bcb-b312-d04cb4299f46","execution":{"iopub.status.busy":"2024-03-13T08:29:09.504523Z","iopub.execute_input":"2024-03-13T08:29:09.505098Z","iopub.status.idle":"2024-03-13T08:29:09.511742Z","shell.execute_reply.started":"2024-03-13T08:29:09.505068Z","shell.execute_reply":"2024-03-13T08:29:09.510794Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 985787\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 867\n    })\n    validation: Dataset({\n        features: ['tokens', 'ner_tags'],\n        num_rows: 13460\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets.column_names","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgT6zo1usFhV","outputId":"7b88f242-c536-4862-8228-cefdd923c927","execution":{"iopub.status.busy":"2024-03-13T08:29:12.244336Z","iopub.execute_input":"2024-03-13T08:29:12.244707Z","iopub.status.idle":"2024-03-13T08:29:12.252940Z","shell.execute_reply.started":"2024-03-13T08:29:12.244675Z","shell.execute_reply":"2024-03-13T08:29:12.251969Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'train': ['tokens', 'ner_tags'],\n 'test': ['tokens', 'ner_tags'],\n 'validation': ['tokens', 'ner_tags']}"},"metadata":{}}]},{"cell_type":"code","source":"# let's print an instance of dataset\nidx=1000\nrec=raw_datasets['train'][idx]\nfor w, t in zip(rec['tokens'],rec['ner_tags']):\n  print('{}\\t{}'.format(w,t))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SaTkFRhhsMsn","outputId":"8f7c7d29-c3a7-473a-d89d-c4e19570f909","execution":{"iopub.status.busy":"2024-03-13T08:29:14.360705Z","iopub.execute_input":"2024-03-13T08:29:14.361103Z","iopub.status.idle":"2024-03-13T08:29:14.371795Z","shell.execute_reply.started":"2024-03-13T08:29:14.361071Z","shell.execute_reply":"2024-03-13T08:29:14.370716Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"सूक्ष्म\t0\n,\t0\nलघु\t0\nएवं\t0\nमध्यम\t0\nउद्यम\t0\n(\t0\nएमएसएमई\t3\n)\t0\nऔर\t0\nसड़क\t3\nपरिवहन\t4\nएवं\t4\nराजमार्ग\t4\nमंत्री\t0\nश्री\t0\nनितिन\t1\nगडकरी\t2\nने\t0\nआज\t0\nजानकारी\t0\nदी\t0\nकि\t0\nउनका\t0\nमंत्रालय\t0\nएक\t0\nकृषि\t0\nएमएसएमई\t0\nनीति\t0\nलाने\t0\nपर\t0\nकाम\t0\nकर\t0\nरहा\t0\nहै\t0\nजो\t0\nस्थानीय\t0\nकच्चे\t0\nमाल\t0\nका\t0\nउपयोग\t0\nकरते\t0\nहुए\t0\nविनिर्माण\t0\nउत्पादों\t0\nके\t0\nलिए\t0\nग्रामीण\t0\n,\t0\nजनजातीय\t0\n,\t0\nकृषि\t0\nऔर\t0\nवन\t0\nक्षेत्रों\t0\nमें\t0\nउद्यमिता\t0\nविकास\t0\nपर\t0\nध्यान\t0\nकेंद्रित\t0\nकरेगी\t0\n।\t0\n","output_type":"stream"}]},{"cell_type":"code","source":"column_names = raw_datasets[\"train\"].column_names\nprint(column_names)\n\nfeatures = raw_datasets[\"train\"].features\nprint(features)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVVjELSLsPln","outputId":"16cb72f8-81fa-418b-c3b8-06cfe220852d","execution":{"iopub.status.busy":"2024-03-13T08:29:18.435212Z","iopub.execute_input":"2024-03-13T08:29:18.435608Z","iopub.status.idle":"2024-03-13T08:29:18.441218Z","shell.execute_reply.started":"2024-03-13T08:29:18.435581Z","shell.execute_reply":"2024-03-13T08:29:18.440310Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['tokens', 'ner_tags']\n{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n","output_type":"stream"}]},{"cell_type":"code","source":"text_column_name = \"tokens\"\nlabel_column_name = \"ner_tags\"","metadata":{"id":"WbHiIPrwsU1Z","execution":{"iopub.status.busy":"2024-03-13T08:29:20.513100Z","iopub.execute_input":"2024-03-13T08:29:20.513713Z","iopub.status.idle":"2024-03-13T08:29:20.517956Z","shell.execute_reply.started":"2024-03-13T08:29:20.513680Z","shell.execute_reply":"2024-03-13T08:29:20.516881Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n\nlabel_list = features[label_column_name].feature.names\n\nlabel_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n\nprint(label_to_id)\n\nnum_labels = len(label_list)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G8vYMvnesX87","outputId":"e73011fb-3997-4f47-a5a7-a687f4258ef2","execution":{"iopub.status.busy":"2024-03-13T08:30:02.280373Z","iopub.execute_input":"2024-03-13T08:30:02.281081Z","iopub.status.idle":"2024-03-13T08:30:02.287464Z","shell.execute_reply.started":"2024-03-13T08:30:02.281024Z","shell.execute_reply":"2024-03-13T08:30:02.286449Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##Training an NER Model with the dataset -- Load Pre-trained Model","metadata":{"id":"cgO6PkBLses4"}},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\nimport numpy as np\n\nconfig = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetuning_task='ner')\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\nmodel = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nJ9nZvgLsfF_","outputId":"4a758bb0-c86a-4257-e80e-de99ba0294a6","execution":{"iopub.status.busy":"2024-03-13T08:30:04.831439Z","iopub.execute_input":"2024-03-13T08:30:04.831805Z","iopub.status.idle":"2024-03-13T08:30:07.842923Z","shell.execute_reply.started":"2024-03-13T08:30:04.831777Z","shell.execute_reply":"2024-03-13T08:30:07.842170Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Tokenize all texts and align the labels with them**","metadata":{"id":"hNCLsRQpst03"}},{"cell_type":"code","source":"# Tokenize all texts and align the labels with them.\npadding = \"max_length\"\ndef tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(\n        examples[text_column_name],\n        padding=padding,\n        truncation=True,\n        max_length=512,\n        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n        is_split_into_words=True,\n    )\n    labels = []\n    for i, label in enumerate(examples[label_column_name]):\n        # print('=====')\n        # print('{} {}'.format(i,label)) #ak\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n            # ignored in the loss function.\n            if word_idx is None:\n                label_ids.append(-100)\n            # We set the label for the first token of each word.\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n            # the label_all_tokens flag.\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"id":"OkVYJwPqswds","execution":{"iopub.status.busy":"2024-03-13T08:30:10.244327Z","iopub.execute_input":"2024-03-13T08:30:10.245089Z","iopub.status.idle":"2024-03-13T08:30:10.255545Z","shell.execute_reply.started":"2024-03-13T08:30:10.245045Z","shell.execute_reply":"2024-03-13T08:30:10.254103Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_datasett = raw_datasets[\"train\"]\ntrain_dataset=train_datasett.select(range(20000))\n\ntrain_dataset = train_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on train dataset\",\n)","metadata":{"id":"rozHxTcOsxwm","execution":{"iopub.status.busy":"2024-03-13T08:30:13.728515Z","iopub.execute_input":"2024-03-13T08:30:13.729223Z","iopub.status.idle":"2024-03-13T08:30:20.866279Z","shell.execute_reply.started":"2024-03-13T08:30:13.729188Z","shell.execute_reply":"2024-03-13T08:30:20.864982Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #0:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fc43aef10394576bc5e66c974fa705c"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #1:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00bff1784ea54abe813d9c2969cf3a33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #3:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e07a791542a345a8bdf88a38b76acafa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on train dataset #2:   0%|          | 0/5 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6fc42c9578c4a8da6ecdea0b12ba642"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Create Data Collator, Metrics**","metadata":{"id":"jjQR1gO4ueHd"}},{"cell_type":"code","source":"eval_dataset = raw_datasets[\"validation\"]\neval_dataset = eval_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on Validation dataset\",\n)","metadata":{"id":"r62oecx5xQP_","execution":{"iopub.status.busy":"2024-03-13T08:30:47.379965Z","iopub.execute_input":"2024-03-13T08:30:47.380807Z","iopub.status.idle":"2024-03-13T08:30:52.270305Z","shell.execute_reply.started":"2024-03-13T08:30:47.380758Z","shell.execute_reply":"2024-03-13T08:30:52.269253Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #0:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ead7c2e96d464134b88c55dca18115e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #1:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d22b4549585549edb38546424e4f2610"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #2:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c27e967b39c48c59c86b8e575548a72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on Validation dataset #3:   0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49160fb956634585920c4702da6f944f"}},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer)","metadata":{"id":"fVnf9dgcs3SL","execution":{"iopub.status.busy":"2024-03-13T08:30:54.932007Z","iopub.execute_input":"2024-03-13T08:30:54.932869Z","iopub.status.idle":"2024-03-13T08:30:54.938657Z","shell.execute_reply.started":"2024-03-13T08:30:54.932831Z","shell.execute_reply":"2024-03-13T08:30:54.937893Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Metrics\nmetric = load_metric(\"seqeval\")\n\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n\n    # Remove ignored index (special tokens)\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n\n    results = metric.compute(predictions=true_predictions, references=true_labels)\n    # Unpack nested dictionaries\n    final_results = {}\n    for key, value in results.items():\n        if isinstance(value, dict):\n            for n, v in value.items():\n                final_results[f\"{key}_{n}\"] = v\n        else:\n            final_results[key] = value\n    return final_results","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJpFUHyqumgY","outputId":"549a0c8e-1224-4569-adea-b805e6eaa205","execution":{"iopub.status.busy":"2024-03-13T08:30:56.883267Z","iopub.execute_input":"2024-03-13T08:30:56.883942Z","iopub.status.idle":"2024-03-13T08:30:57.277961Z","shell.execute_reply.started":"2024-03-13T08:30:56.883910Z","shell.execute_reply":"2024-03-13T08:30:57.277089Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6575dbb67f1453ba309f8e638ab1e53"}},"metadata":{}}]},{"cell_type":"markdown","source":"**Set Training Arguments**","metadata":{"id":"S9gDdCH7uqh_"}},{"cell_type":"code","source":"batch_size=8\nargs=TrainingArguments(\n    output_dir='output_dir',\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    evaluation_strategy = \"epoch\",\n    learning_rate=5e-5)","metadata":{"id":"HMEorS7-uuWx","execution":{"iopub.status.busy":"2024-03-13T08:31:00.373677Z","iopub.execute_input":"2024-03-13T08:31:00.374019Z","iopub.status.idle":"2024-03-13T08:31:00.468190Z","shell.execute_reply.started":"2024-03-13T08:31:00.373993Z","shell.execute_reply":"2024-03-13T08:31:00.467323Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"**Training**","metadata":{"id":"hcE1plDKw3kJ"}},{"cell_type":"code","source":"# Initialize our Trainer\n# early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n# args.metric_for_best_model = \"f1\"\n# args.load_best_model_at_end = True\n# args.evaluation_strategy = IntervalStrategy.STEPS\n# args.eval_steps = args.save_steps\n# args.greater_is_better = True\n\ntrainer = Trainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    # callbacks=[early_stopping_callback],\n    args=args,\n)","metadata":{"id":"7Odpt-7gw5HU","execution":{"iopub.status.busy":"2024-03-13T08:31:02.733802Z","iopub.execute_input":"2024-03-13T08:31:02.734201Z","iopub.status.idle":"2024-03-13T08:31:04.028424Z","shell.execute_reply.started":"2024-03-13T08:31:02.734169Z","shell.execute_reply":"2024-03-13T08:31:04.027424Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.args","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqeWC1kZw_Xt","outputId":"55075fea-aad3-4aa8-c6da-efc51d58eb5b","execution":{"iopub.status.busy":"2024-03-13T08:31:06.936427Z","iopub.execute_input":"2024-03-13T08:31:06.937236Z","iopub.status.idle":"2024-03-13T08:31:06.945645Z","shell.execute_reply.started":"2024-03-13T08:31:06.937199Z","shell.execute_reply":"2024-03-13T08:31:06.944424Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=2,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=None,\nevaluation_strategy=epoch,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=5e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=output_dir/runs/Mar13_08-31-00_6bf864e21969,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3,\noptim=adamw_torch,\noptim_args=None,\noutput_dir=output_dir,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=8,\nper_device_train_batch_size=8,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nresume_from_checkpoint=None,\nrun_name=output_dir,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=steps,\nsave_total_limit=None,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=0,\nweight_decay=0.0,\n)"},"metadata":{}}]},{"cell_type":"code","source":"train_result = trainer.train()\nmetrics = train_result.metrics","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"lDhylsSuxcyb","outputId":"2968289e-1831-4091-a2be-fb3a073083c6","execution":{"iopub.status.busy":"2024-03-13T08:31:11.334607Z","iopub.execute_input":"2024-03-13T08:31:11.334985Z","iopub.status.idle":"2024-03-13T09:30:25.910752Z","shell.execute_reply.started":"2024-03-13T08:31:11.334955Z","shell.execute_reply":"2024-03-13T09:30:25.909781Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240313_083209-aw1spf6f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/prashikrg/huggingface/runs/aw1spf6f' target=\"_blank\">graceful-frost-14</a></strong> to <a href='https://wandb.ai/prashikrg/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/prashikrg/huggingface' target=\"_blank\">https://wandb.ai/prashikrg/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/prashikrg/huggingface/runs/aw1spf6f' target=\"_blank\">https://wandb.ai/prashikrg/huggingface/runs/aw1spf6f</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3750/3750 57:40, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Loc Precision</th>\n      <th>Loc Recall</th>\n      <th>Loc F1</th>\n      <th>Loc Number</th>\n      <th>Org Precision</th>\n      <th>Org Recall</th>\n      <th>Org F1</th>\n      <th>Org Number</th>\n      <th>Per Precision</th>\n      <th>Per Recall</th>\n      <th>Per F1</th>\n      <th>Per Number</th>\n      <th>Overall Precision</th>\n      <th>Overall Recall</th>\n      <th>Overall F1</th>\n      <th>Overall Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.319000</td>\n      <td>0.298102</td>\n      <td>0.690034</td>\n      <td>0.665035</td>\n      <td>0.677304</td>\n      <td>10213</td>\n      <td>0.594140</td>\n      <td>0.418557</td>\n      <td>0.491127</td>\n      <td>9786</td>\n      <td>0.699504</td>\n      <td>0.614118</td>\n      <td>0.654036</td>\n      <td>10568</td>\n      <td>0.667999</td>\n      <td>0.568522</td>\n      <td>0.614259</td>\n      <td>0.910376</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.239200</td>\n      <td>0.261304</td>\n      <td>0.720679</td>\n      <td>0.711152</td>\n      <td>0.715884</td>\n      <td>10213</td>\n      <td>0.582748</td>\n      <td>0.526058</td>\n      <td>0.552954</td>\n      <td>9786</td>\n      <td>0.734439</td>\n      <td>0.678842</td>\n      <td>0.705547</td>\n      <td>10568</td>\n      <td>0.682880</td>\n      <td>0.640724</td>\n      <td>0.661131</td>\n      <td>0.919216</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.202200</td>\n      <td>0.259096</td>\n      <td>0.713632</td>\n      <td>0.732498</td>\n      <td>0.722942</td>\n      <td>10213</td>\n      <td>0.577398</td>\n      <td>0.559166</td>\n      <td>0.568136</td>\n      <td>9786</td>\n      <td>0.723214</td>\n      <td>0.705148</td>\n      <td>0.714067</td>\n      <td>10568</td>\n      <td>0.674233</td>\n      <td>0.667550</td>\n      <td>0.670875</td>\n      <td>0.920830</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"}]},{"cell_type":"code","source":"metrics = trainer.evaluate()\ntrainer.log_metrics(\"eval\", metrics)","metadata":{"id":"ffvo48_ixfrX","colab":{"base_uri":"https://localhost:8080/","height":419},"outputId":"2f771347-01ae-4143-cb0f-5eaef532931b","execution":{"iopub.status.busy":"2024-03-13T09:30:30.547508Z","iopub.execute_input":"2024-03-13T09:30:30.548289Z","iopub.status.idle":"2024-03-13T09:34:40.980523Z","shell.execute_reply.started":"2024-03-13T09:30:30.548255Z","shell.execute_reply":"2024-03-13T09:34:40.979432Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"***** eval metrics *****\n  epoch                   =        3.0\n  eval_LOC_f1             =     0.7229\n  eval_LOC_number         =      10213\n  eval_LOC_precision      =     0.7136\n  eval_LOC_recall         =     0.7325\n  eval_ORG_f1             =     0.5681\n  eval_ORG_number         =       9786\n  eval_ORG_precision      =     0.5774\n  eval_ORG_recall         =     0.5592\n  eval_PER_f1             =     0.7141\n  eval_PER_number         =      10568\n  eval_PER_precision      =     0.7232\n  eval_PER_recall         =     0.7051\n  eval_loss               =     0.2591\n  eval_overall_accuracy   =     0.9208\n  eval_overall_f1         =     0.6709\n  eval_overall_precision  =     0.6742\n  eval_overall_recall     =     0.6675\n  eval_runtime            = 0:04:10.40\n  eval_samples_per_second =     53.754\n  eval_steps_per_second   =      3.363\n","output_type":"stream"}]},{"cell_type":"code","source":"# For answers\nfrom datasets import Dataset\ndata = {'tokens':\n[['इसके', 'अलावा', 'मानेसर-बावल', 'इनवेस्टमेंट', 'रीजन', 'के', 'लिए', 'मास्टर', 'प्लान', 'तैयार', 'किया'], ['महोदय', 'हमारे', 'देश', 'में', 'सारा', 'कामकाज', 'बुल्गारियाई', 'में', 'ही', 'किया', 'जाता', 'है', 'हम', 'वकील', 'सारे', 'दस्तावेज', 'केवल', 'बुल्गारियाई', 'में', 'ही', 'तैयार', 'करते', 'हैं', 'और', 'न्यायालय', 'में', 'भी', 'सभी', 'कार्यवाही', 'बुल्गारियाई', 'में', 'है'], ['भूलने', 'की', 'यह', 'बीमारी', 'अगर', 'हद', 'से', 'ज्यादा', 'बढ़', 'जाए', 'तो', 'यह', 'एक', 'गंभीर', 'रूप', 'धारण', 'कर', 'लेती', 'है'], ['ये', 'भी', 'पढ़ें', 'CAA', 'विरोध-प्रदर्शन', 'पीएम', 'मोदी', 'बोले', '-', 'झूठी', 'अफवाहों', 'में', 'आकर', 'हिंसा', 'ना', 'फैलाएं'], ['महिलाओं', 'के', 'सशक्तिकरण', 'के', 'लिए', 'संसद', 'और', 'विधानसभाओं', 'में', '33', 'प्रतिशत', 'आरक्षण', 'दिए', 'जाने', 'का', 'प्रस्ताव', 'है', '।'], ['मम्मियां', 'उनके', 'मथ्थे', 'पर', 'गिरते', 'हुये', 'बालों', 'को', 'उंगली', 'से', 'बार', 'बार', 'संवारतीं', 'पर', 'वो', 'फिर', 'गिर', 'जाते', '.'], ['इंडेक्स', 'फंड', 'में', 'निवेश', 'करने', 'वालों', 'को', 'ट्रेकिंग', 'एरर', 'से', 'अपने', 'निवेश', 'को', 'सुरक्षित', 'रखने', 'का', 'बेहतर', 'इंतजाम', 'करना', 'चाहिए'], ['पर', 'इस', 'बात', 'को', 'भी', 'दरकिनार', 'नहीं', 'किया', 'जा', 'सकता', 'है', 'कि', 'इन', 'फिल्मों', 'की', 'असफलता', 'का', 'सबसे', 'ज़्यादा', 'नुक़सान', 'उन्हें', 'ही', 'हुआ', '.'], ['इस', 'दौरान', 'वह', 'आज़ादी', 'के', 'नारे', 'भी', 'लगा', 'रही', 'हैं', '।'], ['2', '-', '3', 'किलोमीटर', 'की', 'परिधि', 'में', 'फैले', 'इस', 'छोटे', 'से', 'इलाके', 'ने', 'मलक्का', 'के', '600', 'सालों', 'के', 'इतिहास', 'को', 'समेट', 'रखा', 'है', '.'], ['उन्होंने', 'कहा', 'कि', 'अगर', 'मैं', 'किसी', 'को', 'अपना', 'छात्र', 'बनाता', 'हूं', 'तो', 'उसे', 'अपने', 'बच्चे', 'जैसा', 'मानता', 'हूं', '।'], ['उन्होंने', 'कहा', 'कि', 'अपने', 'गठन', 'के', 'चार', 'दशकों', 'में', 'सोसायटी', 'ने', 'निर्धन', 'और', 'जरूरतमंद', 'लोगों', 'को', 'हरसंभव', 'सहायता', 'प्रदान', 'की', 'है', '।'], ['आज', 'की', 'तारीख', 'है', '10', 'अगस्त', '2018', 'तथा', 'आज', 'इस', 'वर्ष', 'का', '222वां', 'दिन', 'है।', 'इन', '222', 'दिनों', 'में', 'प्रारंग', 'अपने', 'परिवार', 'के', 'जौनपुरवासियों', 'तक', '208', 'लेख', 'पहुंचा', 'चुका', 'है', 'तथा', 'यह', 'लेख', '209वां', 'लेख', 'होगा', '।'], ['उत्तराखंड', 'में', 'चुनाव', 'से', 'पहले', 'नये', 'जिले', 'की', 'चर्चा', 'पर', 'मुख्यमंत्री', 'हरीश', 'रावत', 'ने', 'विराम', 'लगा', 'दिया', 'हैान', 'की', 'है', '.'], ['आप', 'अधिकारियों', 'के', 'नाम,', 'उनके', 'पद,', 'शाखा', 'कार्यालय,', 'प्रोफाइल', 'और', 'फोन', 'नंबर', 'की', 'जानकारी', 'प्राप्त', 'कर', 'सकते', 'हैं', '।'], ['जड़ी', 'बूटी', 'हनीकिल', 'पौधों', 'के', 'लिए', 'honeysuckle', 'और', 'एक', 'ही', 'पौधे', 'सूखे', 'कली', 'या', 'फूलों', 'से', 'संबंधि', 'हैं', '।'], ['रिपोर्ट', 'की', 'माने', 'तो', 'इस', 'पर', 'एक', 'भारतीय', 'अधिकारी', 'ने', 'कहा', 'सरकार', 'विदेशी', 'मोटरसाइकिलों', 'पर', 'आयात', 'शुल्क', 'अधिक', 'लगाती', 'है', 'क्योंकि', 'घरेलू', 'उद्योग', 'को', 'सुरक्षा', 'देने', 'के', 'लिए', 'यह', 'जरूरी', 'है', '.'], ['इस', 'पोस्टर', 'को', 'बस', 'और', 'दीवारों', 'पर', 'चस्पा', 'किया', 'गया', 'हैी', 'है', '।'], ['मेलबर्न', 'खेलों', 'में', 'भारत', 'ने', 'निशोनबाजी', 'में', '16', 'स्वर्ण', 'सहित', '27', 'पदक', 'अपने', 'नाम', 'किए', 'थे'], ['नेताओं', 'के', 'लिए', 'तो', 'हर', 'मौसम', 'ही', 'मुफ़ीद', 'है', 'लेकिन', 'करेंगे', 'वहीं', 'ढाक', 'के', 'तीन', 'पात,', 'इनके', 'यहां', 'तो', 'न', 'सावन', 'सूखे', 'न', 'भादों', 'हरे'], ['#', 'पीएम', 'मोदी', 'ने', 'अपने', 'भाषण', 'में', 'कहा', 'कि', 'हम', 'विकास', 'मानवीयता', 'के', 'साथ', 'चाहते', 'हैं,', '।', 'उन्होंने', 'कहा', 'कि', 'हम', 'देश', 'का', 'वैभव', 'चाहते', 'हैं', 'लेकिन', 'सादगी', 'के', 'धरातल', 'पर'], ['यह', 'वीडियो', '2014', 'के', 'चुनाव', 'से', 'पहले', '2013', 'में', 'पटना', 'की', 'एक', 'रैली', 'के', 'दौरान', 'विस्फोट', 'में', 'मारे', 'गये', 'एक', 'व्यक्ति', 'की', 'पत्नी', 'का', 'है', '।'], ['भीमा-कोरेगांव', 'में', 'दो', 'समुदायों', 'के', 'बीच', 'कल', 'शाम', 'हुई', 'हिंसा', 'में', 'एक', 'व्यक्ति', 'की', 'मौत', 'हो', 'गयी', 'तथा', 'कई', 'अन्य', 'घायल', 'हुए', 'हैं', '।', 'घायलों', 'को', 'शहर', 'के', 'अलग-अलग', 'इलाकों', 'के', 'निजी', 'अस्पतालों', 'में', 'भर्ती', 'कराया', 'गया', 'है', '।'], ['3', '-', 'आज', 'के', 'समय', 'में', 'लोग', 'थोड़ा', 'वजन', 'उठाने', 'से', 'भी', 'कतराते', 'हैं।', 'पर', 'हम', 'आपकी', 'जानकारी', 'के', 'लिए', 'बताते', 'चलें', 'कि', 'आपकी', 'यह', 'गलती', 'आपकी', 'पीठ', 'दर्द', 'का', 'कारण', 'बन', 'सकती', 'हैं', '।'], ['बैंक', 'ने', 'बताया', 'कि', 'मौजूदा', 'वक्त', 'में', 'उसके', '42', 'करोड़', 'सेविंग', 'अकाउंट', 'होल्डर्स', 'हैं', '.']],\n'ner_tags':\n[[0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n}\n\ndataset = Dataset.from_dict(data)","metadata":{"id":"i3lR0ARjGJru","execution":{"iopub.status.busy":"2024-03-13T09:36:17.256377Z","iopub.execute_input":"2024-03-13T09:36:17.256757Z","iopub.status.idle":"2024-03-13T09:36:17.314243Z","shell.execute_reply.started":"2024-03-13T09:36:17.256729Z","shell.execute_reply":"2024-03-13T09:36:17.312987Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenized_test_set = {}\n\n# for lang in raw_datasets:\ntokenized_test_set = dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=4,\n    load_from_cache_file=True,\n    desc=\"Running tokenizer on test dataset of language {0}\".format('hi'),\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["6a3933734e754f35aeb5db5bc75b1ce5","eca0979ed2c340d4a0d10a43fe70e480","867dd089e3834269a9b7ff07d9a4efdd","b7b9d20653494bf0812675c515a59f10","6e69da8e972b4e04a3245924c6c2c8b6","1ff49fcc3d9244a9b2f63df58fcb7a33","1478116babd446adb4cbdd8a39c45b75","ed205612faad4284ae9588ae0325f81e","7dbb4fd5d4f44870ac4a80304e5ef5aa","2a2f1a4d6b1f400b899392d1c3f638d1","9349bf22e8a34e88b33328b72134edd8"]},"id":"yF1PTUiXGJrv","outputId":"4d06c8e9-b716-4794-a327-8dc25dfd5de0","execution":{"iopub.status.busy":"2024-03-13T09:36:19.627544Z","iopub.execute_input":"2024-03-13T09:36:19.627896Z","iopub.status.idle":"2024-03-13T09:36:20.014109Z","shell.execute_reply.started":"2024-03-13T09:36:19.627863Z","shell.execute_reply":"2024-03-13T09:36:20.012983Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"        ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11ab9d72f3f54149a91b2e7a026b4287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76948dbb6d5548d4b5a34d61dc4d4deb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d86f736a1bc4956810aeb8bd86bbcc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Running tokenizer on test dataset of language hi #3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3431b7fa0434a6aaba48716d8ca0e1b"}},"metadata":{}}]},{"cell_type":"code","source":"final_metrics = {}\n\n# for lang in tokenized_test_set:\npredictions, labels, metrics = trainer.predict(tokenized_test_set, metric_key_prefix=lang)\n\nlang_specific_results = {}\nfor key in metrics:\n    if 'overall_precision' in key:\n      lang_specific_results['Precision'] = metrics[key]\n    elif 'overall_recall' in key:\n      lang_specific_results['Recall'] = metrics[key]\n    elif 'overall_f1' in key:\n      lang_specific_results['F1'] = metrics[key]\nfinal_metrics = lang_specific_results","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"ua9VfkATGJrv","outputId":"dde8fd51-34f0-4584-dbd0-546ba14e53ba","execution":{"iopub.status.busy":"2024-03-13T09:36:23.375380Z","iopub.execute_input":"2024-03-13T09:36:23.376236Z","iopub.status.idle":"2024-03-13T09:36:23.945480Z","shell.execute_reply.started":"2024-03-13T09:36:23.376200Z","shell.execute_reply":"2024-03-13T09:36:23.944393Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"print(final_metrics)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFFrQPWlGJrv","outputId":"3eba4197-2d24-4f8f-8989-444eeea8d9ec","execution":{"iopub.status.busy":"2024-03-13T09:36:29.295218Z","iopub.execute_input":"2024-03-13T09:36:29.295564Z","iopub.status.idle":"2024-03-13T09:36:29.302148Z","shell.execute_reply.started":"2024-03-13T09:36:29.295540Z","shell.execute_reply":"2024-03-13T09:36:29.301091Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{'Precision': 0.38461538461538464, 'Recall': 0.8333333333333334, 'F1': 0.5263157894736842}\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained(\"ner_model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:36:33.397407Z","iopub.execute_input":"2024-03-13T09:36:33.397749Z","iopub.status.idle":"2024-03-13T09:36:33.704846Z","shell.execute_reply.started":"2024-03-13T09:36:33.397724Z","shell.execute_reply":"2024-03-13T09:36:33.703741Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"tokenizer\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:36:35.844608Z","iopub.execute_input":"2024-03-13T09:36:35.844977Z","iopub.status.idle":"2024-03-13T09:36:35.928413Z","shell.execute_reply.started":"2024-03-13T09:36:35.844948Z","shell.execute_reply":"2024-03-13T09:36:35.927364Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/spiece.model',\n 'tokenizer/added_tokens.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(label_list)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(label_list)\n}\nprint(id2label)\nprint(label2id)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:36:38.454717Z","iopub.execute_input":"2024-03-13T09:36:38.455347Z","iopub.status.idle":"2024-03-13T09:36:38.463567Z","shell.execute_reply.started":"2024-03-13T09:36:38.455316Z","shell.execute_reply":"2024-03-13T09:36:38.462397Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"{'0': 'O', '1': 'B-PER', '2': 'I-PER', '3': 'B-ORG', '4': 'I-ORG', '5': 'B-LOC', '6': 'I-LOC'}\n{'O': '0', 'B-PER': '1', 'I-PER': '2', 'B-ORG': '3', 'I-ORG': '4', 'B-LOC': '5', 'I-LOC': '6'}\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nconfig=json.load(open(\"/kaggle/working/ner_model/config.json\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:36:40.811044Z","iopub.execute_input":"2024-03-13T09:36:40.811494Z","iopub.status.idle":"2024-03-13T09:36:40.817470Z","shell.execute_reply.started":"2024-03-13T09:36:40.811459Z","shell.execute_reply":"2024-03-13T09:36:40.816385Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"config[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:36:43.676283Z","iopub.execute_input":"2024-03-13T09:36:43.676625Z","iopub.status.idle":"2024-03-13T09:36:43.682991Z","shell.execute_reply.started":"2024-03-13T09:36:43.676599Z","shell.execute_reply":"2024-03-13T09:36:43.681946Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"json.dump(config, open(\"/kaggle/working/ner_model/config.json\",\"w\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:36:46.196757Z","iopub.execute_input":"2024-03-13T09:36:46.197159Z","iopub.status.idle":"2024-03-13T09:36:46.203674Z","shell.execute_reply.started":"2024-03-13T09:36:46.197130Z","shell.execute_reply":"2024-03-13T09:36:46.202642Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\"ner_model\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:36:50.653826Z","iopub.execute_input":"2024-03-13T09:36:50.654199Z","iopub.status.idle":"2024-03-13T09:36:50.723320Z","shell.execute_reply.started":"2024-03-13T09:36:50.654171Z","shell.execute_reply":"2024-03-13T09:36:50.721973Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def get_predictions( sentence, tokenizer, model ):\n  # Let us first tokenize the sentence - split words into subwords\n  tok_sentence = tokenizer(sentence, return_tensors='pt')\n\n  with torch.no_grad():\n    # we will send the tokenized sentence to the model to get predictions\n    logits = model(**tok_sentence).logits.argmax(-1)\n\n    # We will map the maximum predicted class id with the class label\n    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n\n    predicted_labels = []\n\n    previous_token_id = 0\n    # we need to assign the named entity label to the head word and not the following sub-words\n    word_ids = tok_sentence.word_ids()\n    for word_index in range(len(word_ids)):\n        if word_ids[word_index] == None:\n            previous_token_id = word_ids[word_index]\n        elif word_ids[word_index] == previous_token_id:\n            previous_token_id = word_ids[word_index]\n        else:\n            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n            previous_token_id = word_ids[word_index]\n\n    return predicted_labels","metadata":{"id":"Hz7t6AZXGJrv","execution":{"iopub.status.busy":"2024-03-13T09:36:53.647291Z","iopub.execute_input":"2024-03-13T09:36:53.647677Z","iopub.status.idle":"2024-03-13T09:36:53.657554Z","shell.execute_reply.started":"2024-03-13T09:36:53.647648Z","shell.execute_reply":"2024-03-13T09:36:53.656431Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Import all the necessary classes and initialize the tokenizer and model.\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\nmodel = AutoModelForTokenClassification.from_pretrained(\"/kaggle/working/output_dir/checkpoint-3500\")\n","metadata":{"id":"FuEqBXf_GJrw","execution":{"iopub.status.busy":"2024-03-13T09:37:44.160769Z","iopub.execute_input":"2024-03-13T09:37:44.161148Z","iopub.status.idle":"2024-03-13T09:37:46.765266Z","shell.execute_reply.started":"2024-03-13T09:37:44.161117Z","shell.execute_reply":"2024-03-13T09:37:46.764223Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# let us try with some example sentences here\n# sentence = 'लगातार हमलावर हो रहे शिवपाल और राजभर को सपा की दो टूक, चिट्ठी जारी कर कहा- जहां जाना चाहें जा सकते हैं'\nsentences = ['इसके अलावा मानेसर-बावल इनवेस्टमेंट रीजन के लिए मास्टर प्लान  तैयार किया', ' महोदय, हमारे देश में सारा कामकाज बुल्गारियाई में ही किया जाता है हम वकील सारे दस्तावेज केवल बुल्गारियाई में ही तैयार करते हैं और न्यायालय में भी सभी कार्यवाही बुल्गारियाई में होती है.\"', 'भूलने की यह बीमारी अगर हद से ज्यादा बढ़ जाए तो यह एक गंभीर रूप धारण कर लेती है.', 'ये भी पढ़ें: CAA विरोध-प्रदर्शन: पीएम मोदी बोले- झूठी अफवाहों में आकर हिंसा ना फैलाएं', 'महिलाओं के सशक्तिकरण के लिए संसद और विधानसभाओं में 33 प्रतिशत आरक्षण दिए जाने का प्रस्ताव है।', 'मम्मियां उनके मथ्थे पर गिरते हुये बालों को उंगली से बार बार संवारतीं पर वो फिर गिर जाते.', 'इंडेक्स फंड में निवेश करने वालों को ट्रेकिंग एरर से अपने निवेश को सुरक्षित रखने का बेहतर इंतजाम करना चाहिए।', 'पर इस बात को भी दरकिनार नहीं किया जा सकता है कि इन फिल्मों की असफलता का सबसे ज़्यादा नुक़सान उन्हें ही हुआ.', 'इस दौरान वह आज़ादी के नारे भी लगा रही हैं।', '2-3 किलोमीटर की परिधि में फैले इस छोटे से इलाके ने मलक्का के 600 सालों के इतिहास को समेट रखा है.', 'उन्होंने कहा कि अगर मैं किसी को अपना छात्र बनाता हूं तो उसे अपने बच्चे जैसा मानता हूं।', 'उन्होंने कहा कि अपने गठन के चार दशकों में सोसायटी ने निर्धन और जरूरतमंद लोगों को हरसंभव सहायता प्रदान की है।', 'आज की तारीख है 10 अगस्त 2018 तथा आज इस वर्ष का 222वां दिन है। इन 222 दिनों में प्रारंग अपने परिवार के जौनपुरवासियों तक 208 लेख पहुंचा चुका है तथा यह लेख 209वां लेख होगा।', 'उत्तराखंड में चुनाव से पहले नये जिले की चर्चा पर मुख्यमंत्री हरीश रावत ने विराम लगा दिया है.', 'आप अधिकारियों के नाम, उनके पद, शाखा कार्यालय, प्रोफाइल और फोन नंबर की जानकारी प्राप्त कर सकते हैं।', 'जड़ी बूटी हनीकिल पौधों के लिए honeysuckle और एक ही पौधे सूखे कली या फूलों से संबंधित हैं।', 'रिपोर्ट की माने तो इस पर एक भारतीय अधिकारी ने कहा सरकार विदेशी मोटरसाइकिलों पर आयात शुल्क अधिक लगाती है क्योंकि घरेलू उद्योग को सुरक्षा देने के लिए यह जरूरी है.', 'इस पोस्टर को बस और दीवारों पर चस्पा किया गया है।', 'मेलबर्न खेलों में भारत ने निशोनबाजी में 16 स्वर्ण सहित 27 पदक अपने नाम किए थे।', 'नेताओं के लिए तो हर मौसम ही मुफ़ीद है लेकिन करेंगे वहीं ढाक के तीन पात, इनके यहां तो न सावन सूखे न भादों हरे.', '# पीएम मोदी ने अपने भाषण में कहा कि हम विकास मानवीयता के साथ चाहते हैं। उन्होंने कहा कि हम देश का वैभव चाहते हैं लेकिन सादगी के धरातल पर।', 'यह वीडियो 2014 के चुनाव से पहले 2013 में पटना की एक रैली के दौरान विस्फोट में मारे गये एक व्यक्ति की पत्नी का है।', 'भीमा-कोरेगांव में दो समुदायों के बीच कल शाम हुई हिंसा में एक व्यक्ति की मौत हो गयी तथा कई अन्य घायल हुए हैं। घायलों को शहर के अलग-अलग इलाकों के निजी अस्पतालों में भर्ती कराया गया है।', '3- आज के समय में लोग थोड़ा वजन उठाने से भी कतराते हैं। पर हम आपकी जानकारी के लिए बताते चलें कि आपकी यह गलती आपकी पीठ दर्द का कारण बन सकती हैं।', 'बैंक ने बताया कि मौजूदा वक्त में उसके 42 करोड़ सेविंग अकाउंट होल्डर्स हैं.']\n\npred_labels = []\nfor sentence in sentences:\n    predicted_labels = get_predictions(sentence=sentence,\n                                       tokenizer=tokenizer,\n                                       model=model\n                                       )\n    pred_labels.append(predicted_labels)\n","metadata":{"id":"cWojXX3WGJrw","execution":{"iopub.status.busy":"2024-03-13T09:37:51.002118Z","iopub.execute_input":"2024-03-13T09:37:51.004904Z","iopub.status.idle":"2024-03-13T09:37:53.055458Z","shell.execute_reply.started":"2024-03-13T09:37:51.004854Z","shell.execute_reply":"2024-03-13T09:37:53.054253Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(pred_labels)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZxIekV0GJrw","outputId":"e2b05f0c-70a8-4a6f-96c1-d7fde72c1f37","execution":{"iopub.status.busy":"2024-03-13T09:37:56.852414Z","iopub.execute_input":"2024-03-13T09:37:56.852785Z","iopub.status.idle":"2024-03-13T09:37:56.859984Z","shell.execute_reply.started":"2024-03-13T09:37:56.852757Z","shell.execute_reply":"2024-03-13T09:37:56.859059Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"[['LABEL_0', 'LABEL_0', 'LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_3', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_5', 'LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_3', 'LABEL_4', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_3', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_2', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_5', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0'], ['LABEL_1', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0', 'LABEL_0']]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"[['B-LOC', 'B-LOC', 'I-PER', 'B-LOC', 'I-PER', 'O', 'O', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'I-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-ORG', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'I-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['I-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'I-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'I-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['I-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-ORG', 'B-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-ORG', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['I-PER', 'B-LOC', 'B-LOC', 'I-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'I-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-ORG', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'I-PER', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['I-PER', 'O', 'O', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC'], ['B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC', 'B-LOC']]","metadata":{}},{"cell_type":"code","source":"!zip -r ner_model.zip /kaggle/working/ner_model","metadata":{"id":"CTDBKtGKGJrx","execution":{"iopub.status.busy":"2024-03-13T09:38:02.075948Z","iopub.execute_input":"2024-03-13T09:38:02.076369Z","iopub.status.idle":"2024-03-13T09:38:09.993860Z","shell.execute_reply.started":"2024-03-13T09:38:02.076327Z","shell.execute_reply":"2024-03-13T09:38:09.992628Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ner_model/ (stored 0%)\n  adding: kaggle/working/ner_model/config.json (deflated 51%)\n  adding: kaggle/working/ner_model/model.safetensors (deflated 7%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r bert_tokenizer.zip /kaggle/working/ner_model","metadata":{"execution":{"iopub.status.busy":"2024-03-13T09:38:12.112409Z","iopub.execute_input":"2024-03-13T09:38:12.113254Z","iopub.status.idle":"2024-03-13T09:38:20.101027Z","shell.execute_reply.started":"2024-03-13T09:38:12.113218Z","shell.execute_reply":"2024-03-13T09:38:20.099737Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ner_model/ (stored 0%)\n  adding: kaggle/working/ner_model/config.json (deflated 51%)\n  adding: kaggle/working/ner_model/model.safetensors (deflated 7%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r ner_model.zip /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-03-12T14:35:12.755379Z","iopub.execute_input":"2024-03-12T14:35:12.756155Z","iopub.status.idle":"2024-03-12T14:36:51.594951Z","shell.execute_reply.started":"2024-03-12T14:35:12.756124Z","shell.execute_reply":"2024-03-12T14:36:51.593613Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"updating: kaggle/working/ner_model/ (stored 0%)\nupdating: kaggle/working/ner_model/model.safetensors (deflated 7%)\nupdating: kaggle/working/ner_model/config.json (deflated 51%)\n  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/bert_tokenizer.zip (stored 0%)\n  adding: kaggle/working/tokenizer/ (stored 0%)\n  adding: kaggle/working/tokenizer/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/tokenizer/spiece.model (deflated 60%)\n  adding: kaggle/working/tokenizer/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/tokenizer/tokenizer.json (deflated 77%)\n  adding: kaggle/working/wandb/ (stored 0%)\n  adding: kaggle/working/wandb/debug.log (deflated 77%)\n  adding: kaggle/working/wandb/latest-run/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/logs/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/logs/debug.log (deflated 77%)\n  adding: kaggle/working/wandb/latest-run/logs/debug-internal.log (deflated 94%)\n  adding: kaggle/working/wandb/latest-run/tmp/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/tmp/code/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/files/ (stored 0%)\n  adding: kaggle/working/wandb/latest-run/files/wandb-summary.json (deflated 58%)\n  adding: kaggle/working/wandb/latest-run/files/wandb-metadata.json (deflated 68%)\n  adding: kaggle/working/wandb/latest-run/files/config.yaml (deflated 78%)\n  adding: kaggle/working/wandb/latest-run/files/conda-environment.yaml (deflated 67%)\n  adding: kaggle/working/wandb/latest-run/files/output.log (deflated 90%)\n  adding: kaggle/working/wandb/latest-run/files/requirements.txt (deflated 58%)\n  adding: kaggle/working/wandb/latest-run/run-hfhhig8n.wandb (deflated 82%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/ (stored 0%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/logs/ (stored 0%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/logs/debug.log (deflated 77%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/logs/debug-internal.log (deflated 94%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/tmp/ (stored 0%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/tmp/code/ (stored 0%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/files/ (stored 0%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/files/wandb-summary.json (deflated 58%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/files/wandb-metadata.json (deflated 68%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/files/config.yaml (deflated 78%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/files/conda-environment.yaml (deflated 67%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/files/output.log (deflated 90%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/files/requirements.txt (deflated 58%)\n  adding: kaggle/working/wandb/run-20240312_133516-hfhhig8n/run-hfhhig8n.wandb (deflated 82%)\n  adding: kaggle/working/wandb/debug-internal.log (deflated 94%)\n  adding: kaggle/working/output_dir/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-1000/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-1000/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/output_dir/checkpoint-1000/optimizer.pt (deflated 78%)\n  adding: kaggle/working/output_dir/checkpoint-1000/scheduler.pt (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-1000/spiece.model (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-1000/model.safetensors (deflated 7%)\n  adding: kaggle/working/output_dir/checkpoint-1000/training_args.bin (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-1000/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/output_dir/checkpoint-1000/tokenizer.json (deflated 77%)\n  adding: kaggle/working/output_dir/checkpoint-1000/trainer_state.json (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-1000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/output_dir/checkpoint-1000/config.json (deflated 56%)\n  adding: kaggle/working/output_dir/runs/ (stored 0%)\n  adding: kaggle/working/output_dir/runs/Mar12_13-34-09_22e204374a7b/ (stored 0%)\n  adding: kaggle/working/output_dir/runs/Mar12_13-34-09_22e204374a7b/events.out.tfevents.1710253824.22e204374a7b.34.1 (deflated 48%)\n  adding: kaggle/working/output_dir/runs/Mar12_13-34-09_22e204374a7b/events.out.tfevents.1710250482.22e204374a7b.34.0 (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-2000/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-2000/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/output_dir/checkpoint-2000/optimizer.pt (deflated 78%)\n  adding: kaggle/working/output_dir/checkpoint-2000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/output_dir/checkpoint-2000/spiece.model (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-2000/model.safetensors (deflated 7%)\n  adding: kaggle/working/output_dir/checkpoint-2000/training_args.bin (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-2000/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/output_dir/checkpoint-2000/tokenizer.json (deflated 77%)\n  adding: kaggle/working/output_dir/checkpoint-2000/trainer_state.json (deflated 62%)\n  adding: kaggle/working/output_dir/checkpoint-2000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/output_dir/checkpoint-2000/config.json (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-3500/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-3500/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/output_dir/checkpoint-3500/optimizer.pt (deflated 78%)\n  adding: kaggle/working/output_dir/checkpoint-3500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/output_dir/checkpoint-3500/spiece.model (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-3500/model.safetensors (deflated 7%)\n  adding: kaggle/working/output_dir/checkpoint-3500/training_args.bin (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-3500/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/output_dir/checkpoint-3500/tokenizer.json (deflated 77%)\n  adding: kaggle/working/output_dir/checkpoint-3500/trainer_state.json (deflated 68%)\n  adding: kaggle/working/output_dir/checkpoint-3500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/output_dir/checkpoint-3500/config.json (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-500/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-500/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/output_dir/checkpoint-500/optimizer.pt (deflated 79%)\n  adding: kaggle/working/output_dir/checkpoint-500/scheduler.pt (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-500/spiece.model (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-500/model.safetensors (deflated 7%)\n  adding: kaggle/working/output_dir/checkpoint-500/training_args.bin (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-500/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/output_dir/checkpoint-500/tokenizer.json (deflated 77%)\n  adding: kaggle/working/output_dir/checkpoint-500/trainer_state.json (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/output_dir/checkpoint-500/config.json (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-3000/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-3000/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/output_dir/checkpoint-3000/optimizer.pt (deflated 78%)\n  adding: kaggle/working/output_dir/checkpoint-3000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/output_dir/checkpoint-3000/spiece.model (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-3000/model.safetensors (deflated 7%)\n  adding: kaggle/working/output_dir/checkpoint-3000/training_args.bin (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-3000/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/output_dir/checkpoint-3000/tokenizer.json (deflated 77%)\n  adding: kaggle/working/output_dir/checkpoint-3000/trainer_state.json (deflated 67%)\n  adding: kaggle/working/output_dir/checkpoint-3000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/output_dir/checkpoint-3000/config.json (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-1500/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-1500/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/output_dir/checkpoint-1500/optimizer.pt (deflated 78%)\n  adding: kaggle/working/output_dir/checkpoint-1500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/output_dir/checkpoint-1500/spiece.model (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-1500/model.safetensors (deflated 7%)\n  adding: kaggle/working/output_dir/checkpoint-1500/training_args.bin (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-1500/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/output_dir/checkpoint-1500/tokenizer.json (deflated 77%)\n  adding: kaggle/working/output_dir/checkpoint-1500/trainer_state.json (deflated 59%)\n  adding: kaggle/working/output_dir/checkpoint-1500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/output_dir/checkpoint-1500/config.json (deflated 56%)\n  adding: kaggle/working/output_dir/checkpoint-2500/ (stored 0%)\n  adding: kaggle/working/output_dir/checkpoint-2500/special_tokens_map.json (deflated 49%)\n  adding: kaggle/working/output_dir/checkpoint-2500/optimizer.pt (deflated 78%)\n  adding: kaggle/working/output_dir/checkpoint-2500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/output_dir/checkpoint-2500/spiece.model (deflated 60%)\n  adding: kaggle/working/output_dir/checkpoint-2500/model.safetensors (deflated 7%)\n  adding: kaggle/working/output_dir/checkpoint-2500/training_args.bin (deflated 51%)\n  adding: kaggle/working/output_dir/checkpoint-2500/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/output_dir/checkpoint-2500/tokenizer.json (deflated 77%)\n  adding: kaggle/working/output_dir/checkpoint-2500/trainer_state.json (deflated 65%)\n  adding: kaggle/working/output_dir/checkpoint-2500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/output_dir/checkpoint-2500/config.json (deflated 56%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}